{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:28:28.696146Z",
     "start_time": "2020-11-20T09:28:28.691536Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1  Actor,Critic,Baseline network¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:28:28.817688Z",
     "start_time": "2020-11-20T09:28:28.749329Z"
    }
   },
   "outputs": [],
   "source": [
    "activation_dict = {\"relu\": nn.ReLU(),\"sigmoid\": nn.Sigmoid(),\"softmax\": nn.Softmax(),\"selu\": nn.SELU()}\n",
    "\n",
    "#Use feature as the input and output selection probability\n",
    "class Actor(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, h_dim, output_dim, layer_num, activation):\n",
    "        super(Actor, self).__init__()\n",
    "        #add regularization term in loss in pytroch, not every layer in keras\n",
    "        layer_list = []\n",
    "        layer_list.append(nn.Linear(input_dim, h_dim))\n",
    "        layer_list.append(activation_dict[activation])\n",
    "        for _ in range(layer_num - 2):\n",
    "            layer_list.append(nn.Linear(h_dim, h_dim))\n",
    "            layer_list.append(activation_dict[activation])\n",
    "        layer_list.append(nn.Linear(h_dim, output_dim))\n",
    "        layer_list.append(activation_dict[\"sigmoid\"])\n",
    "        \n",
    "        self.linears = nn.Sequential(*layer_list)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linears(x)\n",
    "        \n",
    "#Use selected feature as the input and predict labels    \n",
    "class Critic_RankNet(nn.Module):\n",
    "    def __init__(self, inputs, hidden_size, outputs):\n",
    "        super(Critic_RankNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(inputs, hidden_size),\n",
    "            #nn.Dropout(0.5),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.LeakyReLU(0.2,  inplace=True),#inplace为True，将会改变输入的数据 ，否则不会改变原输入，只会产生新的输出\n",
    "            #nn.SELU(inplace=True),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LeakyReLU(0.2,  inplace=True),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LeakyReLU(0.2,  inplace=True),\n",
    "            nn.Linear(hidden_size, outputs),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_1, selection_1, input_2, selection_2):\n",
    "        \n",
    "        input_1 = np.array(input_1) * np.array(selection_1)\n",
    "        result_1 = self.model(torch.from_numpy(input_1)) #预测input_1得分\n",
    "        \n",
    "        input_2 = np.array(input_2) * np.array(selection_2)\n",
    "        result_2 = self.model(torch.from_numpy(input_2)) #预测input_2得分\n",
    "        \n",
    "        pred = self.sigmoid(result_1 - result_2) #input_1比input_2更相关概率\n",
    "        return pred\n",
    "\n",
    "    def predict(self, input, selection):\n",
    "        \n",
    "        input = np.array(input) * np.array(selection)\n",
    "        result = self.model(torch.from_numpy(input))\n",
    "        return result   \n",
    "\n",
    "#Use the original feature as the input and predict labels\n",
    "class Baseline_RankNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, inputs, hidden_size, outputs):\n",
    "        super(Baseline_RankNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(inputs, hidden_size),\n",
    "            #nn.Dropout(0.5),\n",
    "            #nn.ReLU(inplace=True),\n",
    "            nn.LeakyReLU(0.2,  inplace=True),#inplace为True，将会改变输入的数据 ，否则不会改变原输入，只会产生新的输出\n",
    "            #nn.SELU(inplace=True),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LeakyReLU(0.2,  inplace=True),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.LeakyReLU(0.2,  inplace=True),\n",
    "            nn.Linear(hidden_size, outputs),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input_1, input_2):\n",
    "        \n",
    "        result_1 = self.model(input_1) #预测input_1得分\n",
    "        result_2 = self.model(input_2) #预测input_2得分\n",
    "        pred = self.sigmoid(result_1 - result_2) #input_1比input_2更相关概率\n",
    "        return pred\n",
    "\n",
    "    def predict(self, input):\n",
    "        result = self.model(input)\n",
    "        return result   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2  data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:28:28.891478Z",
     "start_time": "2020-11-20T09:28:28.825029Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(toks):\n",
    "    # 获取features\n",
    "    features = []\n",
    "    for tok in toks:\n",
    "        features.append(float(tok.split(\":\")[1]))\n",
    "    return features\n",
    "\n",
    "def extract_query_data(tok):\n",
    "    #获取queryid documentid\n",
    "    query_features = [tok.split(\":\")[1]] #qid\n",
    "    return query_features\n",
    "\n",
    "def get_format_data(data_path):\n",
    "    with open(data_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data, _, comment = line.rstrip().partition(\"#\")\n",
    "            toks = data.split()\n",
    "            y_train.append(int(toks[0])) #相关度\n",
    "            x_train.append(extract_features(toks[2:])) # doc features\n",
    "            query_id.append(extract_query_data(toks[1])) #qid\n",
    "            \n",
    "\n",
    "def get_pair_doc_data(y_train, query_id):\n",
    "    #两两组合pair\n",
    "    pairs = []\n",
    "    tmp_x0 = []\n",
    "    tmp_y0 = []\n",
    "    tmp_x1 = []\n",
    "    tmp_y1 = []\n",
    "    tmp_within_query_signal = []\n",
    "    \n",
    "    for i in range(0, len(query_id) - 1):\n",
    "        \n",
    "        within_query_signal = 0      \n",
    "        for j in range(i + 1, len(query_id)):\n",
    "            #belongs to same query\n",
    "            if query_id[i][0] == query_id[j][0]:\n",
    "                within_query_signal = 1\n",
    "                \n",
    "            pairs.append([i,j])\n",
    "            tmp_x0.append(x_train[i])\n",
    "            tmp_y0.append(y_train[i])\n",
    "            tmp_x1.append(x_train[j])\n",
    "            tmp_y1.append(y_train[j])\n",
    "            tmp_within_query_signal.append(within_query_signal)\n",
    "\n",
    "    array_train_x0 = np.array(tmp_x0)\n",
    "    array_train_y0 = np.array(tmp_y0)\n",
    "    array_train_x1 = np.array(tmp_x1)\n",
    "    array_train_y1 = np.array(tmp_y1)\n",
    "    array_within_query_signal = np.array(tmp_within_query_signal)\n",
    "    \n",
    "    samples = int(array_train_x0.shape[0] * samples_portion_of_all)\n",
    "    sample_1 = int(samples / 2)\n",
    "    sample_0 = samples - sample_1\n",
    "    \n",
    "    signal_bool = array_within_query_signal.astype(bool)\n",
    "    \n",
    "    array_train_x0_1 = array_train_x0[signal_bool]\n",
    "    array_train_y0_1 = array_train_y0[signal_bool]\n",
    "    array_train_x1_1 = array_train_x1[signal_bool]\n",
    "    array_train_y1_1 = array_train_y1[signal_bool]\n",
    "    array_within_query_signal_1 = array_within_query_signal[signal_bool]\n",
    "    \n",
    "    sample_1_index = np.random.choice(np.arange(array_train_x0_1.shape[0]), sample_1, replace=False)\n",
    "    \n",
    "    tmp_array_train_x0_1 = array_train_x0_1[sample_1_index]\n",
    "    tmp_array_train_y0_1 = array_train_y0_1[sample_1_index]\n",
    "    tmp_array_train_x1_1 = array_train_x1_1[sample_1_index]\n",
    "    tmp_array_train_y1_1 = array_train_y1_1[sample_1_index]\n",
    "    tmp_array_within_query_signal_1 = array_within_query_signal_1[sample_1_index]\n",
    "    #-------------------------------------------------------------------------------------\n",
    "    array_train_x0_0 = array_train_x0[(1-signal_bool).astype(bool)]\n",
    "    array_train_y0_0 = array_train_y0[(1-signal_bool).astype(bool)]\n",
    "    array_train_x1_0 = array_train_x1[(1-signal_bool).astype(bool)]\n",
    "    array_train_y1_0 = array_train_y1[(1-signal_bool).astype(bool)]\n",
    "    array_within_query_signal_0 = array_within_query_signal[(1-signal_bool).astype(bool)]\n",
    "    \n",
    "    sample_0_index = np.random.choice(np.arange(array_train_x0_0.shape[0]), sample_0, replace=False)\n",
    "\n",
    "    tmp_array_train_x0_0 = array_train_x0_0[sample_0_index]\n",
    "    tmp_array_train_y0_0 = array_train_y0_0[sample_0_index]\n",
    "    tmp_array_train_x1_0 = array_train_x1_0[sample_0_index]\n",
    "    tmp_array_train_y1_0 = array_train_y1_0[sample_0_index]\n",
    "    tmp_array_within_query_signal_0 = array_within_query_signal_0[sample_0_index]\n",
    "    \n",
    "    #-----combine----\n",
    "    \n",
    "    new_array_train_x0 = np.vstack((tmp_array_train_x0_1, tmp_array_train_x0_0))\n",
    "    new_array_train_y0 = np.hstack((tmp_array_train_y0_1, tmp_array_train_y0_0))\n",
    "    new_array_train_x1 = np.vstack((tmp_array_train_x1_1, tmp_array_train_x1_0))\n",
    "    new_array_train_y1 = np.hstack((tmp_array_train_y1_1, tmp_array_train_y1_0))\n",
    "    new_array_within_query_signal = np.hstack((tmp_array_within_query_signal_1, tmp_array_within_query_signal_0))\n",
    "    \n",
    "#     samples = int(array_train_x0.shape[0] * samples_portion_of_all)\n",
    "#     samples_index = np.random.choice(np.arange(array_train_x0.shape[0]), samples, replace=False)\n",
    "    \n",
    "#     tmp_array_train_x0 = array_train_x0[samples_index]\n",
    "#     tmp_array_train_y0 = array_train_y0[samples_index]\n",
    "#     tmp_array_train_x1 = array_train_x1[samples_index]\n",
    "#     tmp_array_train_y1 = array_train_y1[samples_index]\n",
    "#     tmp_array_within_query_signal = array_within_query_signal[samples_index]\n",
    "    \n",
    "    return samples, new_array_train_x0, new_array_train_y0, new_array_train_x1, new_array_train_y1, new_array_within_query_signal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dstaset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:28:28.928692Z",
     "start_time": "2020-11-20T09:28:28.899335Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "\n",
    "    def __init__(self, data_path):\n",
    "        # 解析训练数据\n",
    "        get_format_data(data_path)\n",
    "        # pair组合\n",
    "        self.datasize, self.array_train_x0, self.array_train_y0, self.array_train_x1, self.array_train_y1, self.array_within_query_signal = get_pair_doc_data(y_train, query_id)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        data1 = torch.from_numpy(self.array_train_x0[index]).float()\n",
    "        y1 = torch.tensor(self.array_train_y0[index]).float()\n",
    "        \n",
    "        data2 = torch.from_numpy(self.array_train_x1[index]).float()\n",
    "        y2 = torch.tensor(self.array_train_y1[index]).float()\n",
    "        \n",
    "        signal = torch.tensor(self.array_within_query_signal[index]).float()\n",
    "        \n",
    "        return data1, y1, data2, y2, signal\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datasize\n",
    "\n",
    "def get_loader(data_path, batch_size, shuffle, drop_last):\n",
    "    \n",
    "    dataset = Dataset(data_path)\n",
    "    \n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset=dataset,\n",
    "        batch_size = batch_size,\n",
    "        shuffle = shuffle,\n",
    "        drop_last=drop_last\n",
    "    )\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:28:29.039268Z",
     "start_time": "2020-11-20T09:28:28.934335Z"
    }
   },
   "outputs": [],
   "source": [
    "# path = \"./MQ2008/Fold{}/\".format(1)\n",
    "\n",
    "# y_train = []\n",
    "# x_train = []\n",
    "# query_id = []\n",
    "# array_train_x1 = []\n",
    "# array_train_x0 = []\n",
    "\n",
    "# samples_portion_of_all = 0.0001\n",
    "\n",
    "# train_path = path + 'train.txt'\n",
    "# train_loader = get_loader(train_path, 128, shuffle=True, drop_last=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:28:29.097804Z",
     "start_time": "2020-11-20T09:28:29.042298Z"
    }
   },
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# signal_matrix = []\n",
    "# for batch, (data1, y1, data2, y2, signal) in enumerate(train_loader):\n",
    "    \n",
    "#     print(data1.shape)\n",
    "#     print(y1.shape)\n",
    "#     print(data2.shape)\n",
    "#     print(y2.shape)\n",
    "#     print(signal.shape)\n",
    "#     print(signal)\n",
    "#     signal_matrix.append(signal)\n",
    "#     i = i + 1\n",
    "#     print(\"-----------------------------\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:28:29.173071Z",
     "start_time": "2020-11-20T09:28:29.100325Z"
    }
   },
   "outputs": [],
   "source": [
    "# count_1 = 0\n",
    "# for i in range(len(signal_matrix)):\n",
    "    \n",
    "#     count_1  = count_1 + signal_matrix[i].sum()\n",
    "    \n",
    "#     print(signal_matrix[i].sum() / len(signal_matrix[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:28:29.229924Z",
     "start_time": "2020-11-20T09:28:29.175809Z"
    }
   },
   "outputs": [],
   "source": [
    "# count_1 / (len(signal_matrix) * len(signal_matrix[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of Loss and Training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:28:29.307381Z",
     "start_time": "2020-11-20T09:28:29.232995Z"
    }
   },
   "outputs": [],
   "source": [
    "def pair_actor_loss(actor_output_1, actor_output_2, selection_1, selection_2, critic_loss_1, critic_loss_2, baseline_loss_1, baseline_loss_2, signal, lamda, beta, gamma):\n",
    "\n",
    "    m = torch.nn.Softmax(dim=1)\n",
    "    \n",
    "    Reward_1 = critic_loss_1 - baseline_loss_1\n",
    "    Pi_1 = (selection_1 * torch.log(actor_output_1 + 1e-8) + (1-selection_1) * torch.log(1-actor_output_1 + 1e-8)).sum(1)\n",
    "    L0_1 = actor_output_1.detach().mean(1)\n",
    "#     custom_actor_loss_1 = Pi_1 * Reward_1 + lamda * L0_1\n",
    "#     L0_1 = selection_1.mean(1)\n",
    "    custom_actor_loss_1 = Pi_1 * Reward_1 + lamda * L0_1\n",
    "    #*************************************************************************\n",
    "    Reward_2 = critic_loss_2 - baseline_loss_2\n",
    "    Pi_2 = (selection_2 * torch.log(actor_output_2 + 1e-8) + (1-selection_2) * torch.log(1-actor_output_2 + 1e-8)).sum(1)\n",
    "    L0_2 = actor_output_2.detach().mean(1)\n",
    "#     custom_actor_loss_2 = Pi_2 * Reward_2 + lamda * L0_2\n",
    "#     L0_2 = selection_2.mean(1)\n",
    "    custom_actor_loss_2 = Pi_2 * Reward_2 + lamda * L0_2\n",
    "    #***************************************************************************\n",
    "    \n",
    "    actor_output_1 = m(actor_output_1)\n",
    "    actor_output_2 = m(actor_output_2)\n",
    "    \n",
    "    selection_loss = -((actor_output_1 * torch.log(actor_output_2 + 1e-8) + (1-actor_output_1) * torch.log(1-actor_output_2 + 1e-8))).sum(1)\n",
    "\n",
    "#     final_selection_loss = beta * (selection_loss * signal) - gamma * (selection_loss * (1 - signal))\n",
    "\n",
    "#     print(selection_loss.shape)\n",
    "#     print(signal.shape)\n",
    "#     print(\"-------------\")\n",
    "    \n",
    "    signal_beta = signal.type(torch.bool)\n",
    "    signal_gamma = (1 - signal).type(torch.bool)\n",
    "    final_selection_loss = torch.FloatTensor(selection_loss.size()).type_as(selection_loss)\n",
    "    \n",
    "    final_selection_loss[signal_beta] = beta * selection_loss[signal_beta]\n",
    "    final_selection_loss[signal_gamma] = -gamma * selection_loss[signal_gamma]\n",
    "    \n",
    "    \n",
    "    return ((custom_actor_loss_1.mean() + custom_actor_loss_2.mean())/2) + final_selection_loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:28:29.424397Z",
     "start_time": "2020-11-20T09:28:29.310801Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(baseline_model, actor_model,critic_model, epochs, lamda, beta, gamma):\n",
    "        \n",
    "    actor_optimizer = torch.optim.Adam(actor_model.parameters(),lr = 1e-5, weight_decay=1e-5)\n",
    "    critic_optimizer = torch.optim.Adam(critic_model.parameters(),lr = 1e-4, weight_decay=1e-5)\n",
    "    baseline_optimizer = torch.optim.Adam(baseline_model.parameters(),lr = 1e-4, weight_decay=1e-5)\n",
    "    \n",
    "    critic_criterion = nn.BCELoss()\n",
    "    baseline_criterion = nn.BCELoss()\n",
    "    loss_criterion = nn.BCELoss()\n",
    "    #restrict_f = nn.Sigmoid()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        epoch_train_actor_loss_output = []\n",
    "\n",
    "        for batch, (data1, y1, data2, y2, signal) in enumerate(train_loader):\n",
    "            \n",
    "#             sampled_index = np.random.choice(np.arange(data1.shape[0]), samples_in_batch, replace=False)\n",
    "            \n",
    "#             data1 = data1[sampled_index]\n",
    "#             y1 = y1[sampled_index]\n",
    "#             data2 = data2[sampled_index]\n",
    "#             y2 = y2[sampled_index]\n",
    "#             signal = signal[sampled_index]\n",
    "            \n",
    "            # get selections of data1 and data2\n",
    "            actor_output_1 = actor_model(data1.float())\n",
    "            selection_1 = torch.bernoulli(torch.tensor(actor_output_1))\n",
    "            \n",
    "            actor_output_2 = actor_model(data2.float())\n",
    "            selection_2 = torch.bernoulli(torch.tensor(actor_output_2))\n",
    "\n",
    "            # train critic model\n",
    "            critic_output = critic_model(data1.float(), selection_1, data2.float(), selection_2)\n",
    "            \n",
    "            label_difference = y1.ge(y2).double()\n",
    "            critic_loss_output = critic_criterion(critic_output.double(), label_difference)\n",
    "\n",
    "            critic_optimizer.zero_grad()\n",
    "            critic_loss_output.backward()\n",
    "            critic_optimizer.step()\n",
    "            \n",
    "            critic_output_1 = critic_model.predict(data1.float(), selection_1)\n",
    "            critic_output_2 = critic_model.predict(data2.float(), selection_2)\n",
    "            \n",
    "            # train basseline model\n",
    "            baseline_output = baseline_model(data1.float(), data2.float())\n",
    "            baseline_loss_output = baseline_criterion(baseline_output.double(), label_difference)\n",
    "\n",
    "            baseline_optimizer.zero_grad()\n",
    "            baseline_loss_output.backward()\n",
    "            baseline_optimizer.step()\n",
    "            \n",
    "            baseline_output_1 = baseline_model.predict(data1.float())\n",
    "            baseline_output_2 = baseline_model.predict(data2.float())\n",
    "\n",
    "            critic_loss_1 = -((y1.ge(1).float().view(-1,1) * torch.log(critic_output_1 + 1e-8)) + (1-y1.ge(1).float().view(-1,1)) * torch.log(1 - critic_output_1 + 1e-8))\n",
    "            critic_loss_2 = -((y2.ge(1).float().view(-1,1) * torch.log(critic_output_2 + 1e-8)) + (1-y2.ge(1).float().view(-1,1)) * torch.log(1 - critic_output_2 + 1e-8))\n",
    "                        \n",
    "            baseline_loss_1 = -((y1.ge(1).float().view(-1,1) * torch.log(baseline_output_1 + 1e-8)) + (1-y1.ge(1).float().view(-1,1)) * torch.log(1 - baseline_output_1 + 1e-8))\n",
    "            baseline_loss_2 = -((y2.ge(1).float().view(-1,1) * torch.log(baseline_output_2 + 1e-8)) + (1-y2.ge(1).float().view(-1,1)) * torch.log(1 - baseline_output_2 + 1e-8))\n",
    "        \n",
    "            # update selector network\n",
    "            actor_loss_output = pair_actor_loss(actor_output_1, actor_output_2, selection_1, selection_2, critic_loss_1, critic_loss_2, baseline_loss_1, baseline_loss_2, signal, lamda, beta, gamma)\n",
    "                        \n",
    "            actor_optimizer.zero_grad()\n",
    "            actor_loss_output.backward()\n",
    "            actor_optimizer.step()\n",
    "            \n",
    "            epoch_train_actor_loss_output.append(actor_loss_output.item())\n",
    "            \n",
    "        print(epoch+1,\"***********************************************************************\")\n",
    "        print(\"---------------train actor loss-------------\", np.mean(epoch_train_actor_loss_output))\n",
    "            \n",
    "        epoch_vali_actor_loss_output = []\n",
    "        epoch_vali_critic_acc = []\n",
    "        \n",
    "        with torch.no_grad():   \n",
    "            for batch, (data1, y1, data2, y2, signal) in enumerate(vali_loader):\n",
    "                \n",
    "                actor_model.eval()\n",
    "                critic_model.eval()\n",
    "                baseline_model.eval()\n",
    "                \n",
    "#                 sampled_index = np.random.choice(np.arange(data1.shape[0]), samples_in_batch, replace=False)\n",
    "                \n",
    "#                 data1 = data1[sampled_index]\n",
    "#                 y1 = y1[sampled_index]\n",
    "#                 data2 = data2[sampled_index]\n",
    "#                 y2 = y2[sampled_index]\n",
    "#                 signal = signal[sampled_index]\n",
    "                \n",
    "                vali_actor_output_1 = actor_model(data1.float())\n",
    "                vali_selection_1 = torch.bernoulli(torch.tensor(vali_actor_output_1))\n",
    "                vali_actor_output_2 = actor_model(data2.float())\n",
    "                vali_selection_2 = torch.bernoulli(torch.tensor(vali_actor_output_2))\n",
    "\n",
    "                vali_critic_output_1 = critic_model.predict(data1.float(), vali_selection_1)\n",
    "                vali_critic_output_2 = critic_model.predict(data2.float(), vali_selection_2)\n",
    "                vali_baseline_output_1 = baseline_model.predict(data1.float())\n",
    "                vali_baseline_output_2 = baseline_model.predict(data2.float())\n",
    "                \n",
    "                \n",
    "                vali_critic_loss_1 = -((y1.ge(1).float().view(-1,1) * torch.log(vali_critic_output_1 + 1e-8)) + (1-y1.ge(1).float().view(-1,1)) * torch.log(1 - vali_critic_output_1 + 1e-8))\n",
    "                vali_critic_loss_2 = -((y2.ge(1).float().view(-1,1) * torch.log(vali_critic_output_2 + 1e-8)) + (1-y2.ge(1).float().view(-1,1)) * torch.log(1 - vali_critic_output_2 + 1e-8))\n",
    "                vali_baseline_loss_1 = -((y1.ge(1).float().view(-1,1) * torch.log(vali_baseline_output_1 + 1e-8)) + (1-y1.ge(1).float().view(-1,1)) * torch.log(1 - vali_baseline_output_1 + 1e-8))\n",
    "                vali_baseline_loss_2 = -((y2.ge(1).float().view(-1,1) * torch.log(vali_baseline_output_2 + 1e-8)) + (1-y2.ge(1).float().view(-1,1)) * torch.log(1 - vali_baseline_output_2 + 1e-8))\n",
    "        \n",
    "                vali_actor_loss_output = pair_actor_loss(vali_actor_output_1, vali_actor_output_2, vali_selection_1, vali_selection_2, vali_critic_loss_1, vali_critic_loss_2, vali_baseline_loss_1, vali_baseline_loss_2, signal, lamda, beta, gamma)\n",
    "\n",
    "                epoch_vali_actor_loss_output.append(vali_actor_loss_output)                \n",
    "            \n",
    "        print(\"---------------Vali actor loss-------------\", np.mean(epoch_vali_actor_loss_output))\n",
    "        #print(\"---------------Critic Accuracy-------------\", np.mean(epoch_vali_critic_acc))\n",
    "\n",
    "    return actor_model,critic_model,baseline_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T09:28:29.469039Z",
     "start_time": "2020-11-20T09:28:29.441115Z"
    }
   },
   "outputs": [],
   "source": [
    "model_para = {'lambda':0.3,\n",
    "              'actor_h_dim':300,\n",
    "              'critic_h_dim':200,\n",
    "              'baseline_h_dim':200,\n",
    "              'actor_output' :46,\n",
    "              'critic_output':1,\n",
    "              'baseline_output':1,\n",
    "              'n_layer':3,\n",
    "              'activation':'selu',\n",
    "              'learning_rate':0.0001}\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T11:03:05.877038Z",
     "start_time": "2020-11-20T09:28:29.483376Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/zhang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/zhang/anaconda3/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ***********************************************************************\n",
      "---------------train actor loss------------- 1.8139257671104536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/zhang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Vali actor loss------------- 5.556114\n",
      "2 ***********************************************************************\n",
      "---------------train actor loss------------- 4.212645785676108\n",
      "---------------Vali actor loss------------- 4.675141\n",
      "3 ***********************************************************************\n",
      "---------------train actor loss------------- 8.506551631208923\n",
      "---------------Vali actor loss------------- 12.354296\n",
      "4 ***********************************************************************\n",
      "---------------train actor loss------------- 10.20561629285415\n",
      "---------------Vali actor loss------------- 15.93807\n",
      "5 ***********************************************************************\n",
      "---------------train actor loss------------- 8.354149093644487\n",
      "---------------Vali actor loss------------- 10.016978\n",
      "6 ***********************************************************************\n",
      "---------------train actor loss------------- 8.64314897151457\n",
      "---------------Vali actor loss------------- 7.5739417\n",
      "7 ***********************************************************************\n",
      "---------------train actor loss------------- 9.761894512921572\n",
      "---------------Vali actor loss------------- 12.695086\n",
      "8 ***********************************************************************\n",
      "---------------train actor loss------------- 8.965453282826477\n",
      "---------------Vali actor loss------------- 16.303574\n",
      "9 ***********************************************************************\n",
      "---------------train actor loss------------- 10.336574866539902\n",
      "---------------Vali actor loss------------- 7.879382\n",
      "10 ***********************************************************************\n",
      "---------------train actor loss------------- 11.883021677326825\n",
      "---------------Vali actor loss------------- 8.244422\n",
      "11 ***********************************************************************\n",
      "---------------train actor loss------------- 7.830011112822427\n",
      "---------------Vali actor loss------------- 9.346434\n",
      "12 ***********************************************************************\n",
      "---------------train actor loss------------- 11.774217774884569\n",
      "---------------Vali actor loss------------- 6.6840315\n",
      "13 ***********************************************************************\n",
      "---------------train actor loss------------- 9.62387160708507\n",
      "---------------Vali actor loss------------- 8.578794\n",
      "14 ***********************************************************************\n",
      "---------------train actor loss------------- 8.684465932763285\n",
      "---------------Vali actor loss------------- 10.90962\n",
      "15 ***********************************************************************\n",
      "---------------train actor loss------------- 9.100247231829497\n",
      "---------------Vali actor loss------------- 8.879152\n",
      "16 ***********************************************************************\n",
      "---------------train actor loss------------- 7.150087279164129\n",
      "---------------Vali actor loss------------- 6.8802886\n",
      "17 ***********************************************************************\n",
      "---------------train actor loss------------- 7.401275546600421\n",
      "---------------Vali actor loss------------- 6.7838244\n",
      "18 ***********************************************************************\n",
      "---------------train actor loss------------- 5.520893140385549\n",
      "---------------Vali actor loss------------- 4.0623937\n",
      "19 ***********************************************************************\n",
      "---------------train actor loss------------- 6.371283000542058\n",
      "---------------Vali actor loss------------- 1.3186055\n",
      "20 ***********************************************************************\n",
      "---------------train actor loss------------- 3.247079723411136\n",
      "---------------Vali actor loss------------- 14.638031\n",
      "21 ***********************************************************************\n",
      "---------------train actor loss------------- 4.423911999083227\n",
      "---------------Vali actor loss------------- 9.977935\n",
      "22 ***********************************************************************\n",
      "---------------train actor loss------------- 7.002703769546416\n",
      "---------------Vali actor loss------------- 15.0644245\n",
      "23 ***********************************************************************\n",
      "---------------train actor loss------------- 8.67251710759269\n",
      "---------------Vali actor loss------------- 12.028166\n",
      "24 ***********************************************************************\n",
      "---------------train actor loss------------- 8.009545178463062\n",
      "---------------Vali actor loss------------- 3.7035494\n",
      "25 ***********************************************************************\n",
      "---------------train actor loss------------- 9.12907496177488\n",
      "---------------Vali actor loss------------- 11.390119\n",
      "26 ***********************************************************************\n",
      "---------------train actor loss------------- 10.774515238073137\n",
      "---------------Vali actor loss------------- -0.2039594\n",
      "27 ***********************************************************************\n",
      "---------------train actor loss------------- 7.0617438770002785\n",
      "---------------Vali actor loss------------- 6.4762526\n",
      "28 ***********************************************************************\n",
      "---------------train actor loss------------- 6.534337097158034\n",
      "---------------Vali actor loss------------- 9.053972\n",
      "29 ***********************************************************************\n",
      "---------------train actor loss------------- 9.662957710938322\n",
      "---------------Vali actor loss------------- 6.1680417\n",
      "30 ***********************************************************************\n",
      "---------------train actor loss------------- 11.487955770972702\n",
      "---------------Vali actor loss------------- 9.984134\n",
      "31 ***********************************************************************\n",
      "---------------train actor loss------------- 9.664554946538475\n",
      "---------------Vali actor loss------------- 12.474515\n",
      "32 ***********************************************************************\n",
      "---------------train actor loss------------- 14.560055447121462\n",
      "---------------Vali actor loss------------- 10.349172\n",
      "33 ***********************************************************************\n",
      "---------------train actor loss------------- 13.172460987336105\n",
      "---------------Vali actor loss------------- 21.038567\n",
      "34 ***********************************************************************\n",
      "---------------train actor loss------------- 16.306916864381897\n",
      "---------------Vali actor loss------------- 3.0124424\n",
      "35 ***********************************************************************\n",
      "---------------train actor loss------------- 12.777357418090105\n",
      "---------------Vali actor loss------------- 16.157673\n",
      "36 ***********************************************************************\n",
      "---------------train actor loss------------- 14.642788857635525\n",
      "---------------Vali actor loss------------- 18.931702\n",
      "37 ***********************************************************************\n",
      "---------------train actor loss------------- 13.511883297728168\n",
      "---------------Vali actor loss------------- 10.692269\n",
      "38 ***********************************************************************\n",
      "---------------train actor loss------------- 15.458645794540644\n",
      "---------------Vali actor loss------------- 26.569967\n",
      "39 ***********************************************************************\n",
      "---------------train actor loss------------- 18.165951799187397\n",
      "---------------Vali actor loss------------- 26.024712\n",
      "40 ***********************************************************************\n",
      "---------------train actor loss------------- 13.830047966705429\n",
      "---------------Vali actor loss------------- 21.29309\n",
      "41 ***********************************************************************\n",
      "---------------train actor loss------------- 13.592341420551142\n",
      "---------------Vali actor loss------------- 21.479095\n",
      "42 ***********************************************************************\n",
      "---------------train actor loss------------- 16.12184003740549\n",
      "---------------Vali actor loss------------- 22.208473\n",
      "43 ***********************************************************************\n",
      "---------------train actor loss------------- 18.72012637058894\n",
      "---------------Vali actor loss------------- 14.3896055\n",
      "44 ***********************************************************************\n",
      "---------------train actor loss------------- 19.125060679184067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Vali actor loss------------- 20.427095\n",
      "45 ***********************************************************************\n",
      "---------------train actor loss------------- 16.51505141788059\n",
      "---------------Vali actor loss------------- 20.121918\n",
      "46 ***********************************************************************\n",
      "---------------train actor loss------------- 17.727015479985212\n",
      "---------------Vali actor loss------------- 24.402466\n",
      "47 ***********************************************************************\n",
      "---------------train actor loss------------- 16.441030143863625\n",
      "---------------Vali actor loss------------- 27.80291\n",
      "48 ***********************************************************************\n",
      "---------------train actor loss------------- 17.71500444329447\n",
      "---------------Vali actor loss------------- 34.63669\n",
      "49 ***********************************************************************\n",
      "---------------train actor loss------------- 16.763349940793383\n",
      "---------------Vali actor loss------------- 23.637526\n",
      "50 ***********************************************************************\n",
      "---------------train actor loss------------- 18.75507719980346\n",
      "---------------Vali actor loss------------- 22.994585\n",
      "51 ***********************************************************************\n",
      "---------------train actor loss------------- 19.002315124703777\n",
      "---------------Vali actor loss------------- 21.6923\n",
      "52 ***********************************************************************\n",
      "---------------train actor loss------------- 21.550515672398937\n",
      "---------------Vali actor loss------------- 18.827291\n",
      "53 ***********************************************************************\n",
      "---------------train actor loss------------- 17.866657704114914\n",
      "---------------Vali actor loss------------- 22.555721\n",
      "54 ***********************************************************************\n",
      "---------------train actor loss------------- 20.548320821589893\n",
      "---------------Vali actor loss------------- 23.420078\n",
      "55 ***********************************************************************\n",
      "---------------train actor loss------------- 19.772584097252953\n",
      "---------------Vali actor loss------------- 21.064342\n",
      "56 ***********************************************************************\n",
      "---------------train actor loss------------- 22.349133264687325\n",
      "---------------Vali actor loss------------- 31.210497\n",
      "57 ***********************************************************************\n",
      "---------------train actor loss------------- 23.774831826488178\n",
      "---------------Vali actor loss------------- 31.876268\n",
      "58 ***********************************************************************\n",
      "---------------train actor loss------------- 23.576846041613155\n",
      "---------------Vali actor loss------------- 32.19584\n",
      "59 ***********************************************************************\n",
      "---------------train actor loss------------- 25.490934758964514\n",
      "---------------Vali actor loss------------- 39.12113\n",
      "60 ***********************************************************************\n",
      "---------------train actor loss------------- 21.87963987348808\n",
      "---------------Vali actor loss------------- 34.174038\n",
      "61 ***********************************************************************\n",
      "---------------train actor loss------------- 26.383682399988174\n",
      "---------------Vali actor loss------------- 23.539906\n",
      "62 ***********************************************************************\n",
      "---------------train actor loss------------- 24.36881564723121\n",
      "---------------Vali actor loss------------- 21.428421\n",
      "63 ***********************************************************************\n",
      "---------------train actor loss------------- 25.054903730750084\n",
      "---------------Vali actor loss------------- 28.815386\n",
      "64 ***********************************************************************\n",
      "---------------train actor loss------------- 27.617854913075764\n",
      "---------------Vali actor loss------------- 31.761183\n",
      "65 ***********************************************************************\n",
      "---------------train actor loss------------- 33.01953315817647\n",
      "---------------Vali actor loss------------- 34.335854\n",
      "66 ***********************************************************************\n",
      "---------------train actor loss------------- 24.427184521324104\n",
      "---------------Vali actor loss------------- 38.775795\n",
      "67 ***********************************************************************\n",
      "---------------train actor loss------------- 27.39467502716515\n",
      "---------------Vali actor loss------------- 34.912693\n",
      "68 ***********************************************************************\n",
      "---------------train actor loss------------- 31.655539471242164\n",
      "---------------Vali actor loss------------- 37.371655\n",
      "69 ***********************************************************************\n",
      "---------------train actor loss------------- 30.156697034835815\n",
      "---------------Vali actor loss------------- 33.92395\n",
      "70 ***********************************************************************\n",
      "---------------train actor loss------------- 26.157286514010693\n",
      "---------------Vali actor loss------------- 43.199795\n",
      "71 ***********************************************************************\n",
      "---------------train actor loss------------- 31.59556014670266\n",
      "---------------Vali actor loss------------- 19.296444\n",
      "72 ***********************************************************************\n",
      "---------------train actor loss------------- 32.91427939178215\n",
      "---------------Vali actor loss------------- 49.333794\n",
      "73 ***********************************************************************\n",
      "---------------train actor loss------------- 32.70630374219682\n",
      "---------------Vali actor loss------------- 44.62412\n",
      "74 ***********************************************************************\n",
      "---------------train actor loss------------- 33.48281556367874\n",
      "---------------Vali actor loss------------- 28.92963\n",
      "75 ***********************************************************************\n",
      "---------------train actor loss------------- 32.338038954469894\n",
      "---------------Vali actor loss------------- 33.13277\n",
      "76 ***********************************************************************\n",
      "---------------train actor loss------------- 33.10922694040669\n",
      "---------------Vali actor loss------------- 37.482113\n",
      "77 ***********************************************************************\n",
      "---------------train actor loss------------- 30.47472180922826\n",
      "---------------Vali actor loss------------- 26.216444\n",
      "78 ***********************************************************************\n",
      "---------------train actor loss------------- 36.94866383241283\n",
      "---------------Vali actor loss------------- 37.1466\n",
      "79 ***********************************************************************\n",
      "---------------train actor loss------------- 34.01219433214929\n",
      "---------------Vali actor loss------------- 66.558304\n",
      "80 ***********************************************************************\n",
      "---------------train actor loss------------- 35.29881218075752\n",
      "---------------Vali actor loss------------- 47.49503\n",
      "81 ***********************************************************************\n",
      "---------------train actor loss------------- 32.69605812844303\n",
      "---------------Vali actor loss------------- 52.03526\n",
      "82 ***********************************************************************\n",
      "---------------train actor loss------------- 33.40715852710936\n",
      "---------------Vali actor loss------------- 43.2941\n",
      "83 ***********************************************************************\n",
      "---------------train actor loss------------- 36.06597169240316\n",
      "---------------Vali actor loss------------- 47.272545\n",
      "84 ***********************************************************************\n",
      "---------------train actor loss------------- 35.456287364164986\n",
      "---------------Vali actor loss------------- 38.420475\n",
      "85 ***********************************************************************\n",
      "---------------train actor loss------------- 37.10831768065691\n",
      "---------------Vali actor loss------------- 53.291557\n",
      "86 ***********************************************************************\n",
      "---------------train actor loss------------- 39.175915564099945\n",
      "---------------Vali actor loss------------- 54.201214\n",
      "87 ***********************************************************************\n",
      "---------------train actor loss------------- 37.53342133429315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Vali actor loss------------- 39.70521\n",
      "88 ***********************************************************************\n",
      "---------------train actor loss------------- 39.384379694859184\n",
      "---------------Vali actor loss------------- 57.479813\n",
      "89 ***********************************************************************\n",
      "---------------train actor loss------------- 41.09884902172618\n",
      "---------------Vali actor loss------------- 38.28691\n",
      "90 ***********************************************************************\n",
      "---------------train actor loss------------- 36.1516997002893\n",
      "---------------Vali actor loss------------- 50.97658\n",
      "91 ***********************************************************************\n",
      "---------------train actor loss------------- 39.21498749653498\n",
      "---------------Vali actor loss------------- 28.54371\n",
      "92 ***********************************************************************\n",
      "---------------train actor loss------------- 40.42731208354235\n",
      "---------------Vali actor loss------------- 56.291542\n",
      "93 ***********************************************************************\n",
      "---------------train actor loss------------- 44.78963102234734\n",
      "---------------Vali actor loss------------- 49.28456\n",
      "94 ***********************************************************************\n",
      "---------------train actor loss------------- 40.80654964182112\n",
      "---------------Vali actor loss------------- 41.163734\n",
      "95 ***********************************************************************\n",
      "---------------train actor loss------------- 42.80109546581904\n",
      "---------------Vali actor loss------------- 53.675987\n",
      "96 ***********************************************************************\n",
      "---------------train actor loss------------- 46.21333803070916\n",
      "---------------Vali actor loss------------- 58.916336\n",
      "97 ***********************************************************************\n",
      "---------------train actor loss------------- 43.89241063594818\n",
      "---------------Vali actor loss------------- 42.527287\n",
      "98 ***********************************************************************\n",
      "---------------train actor loss------------- 38.62309053374661\n",
      "---------------Vali actor loss------------- 46.15768\n",
      "99 ***********************************************************************\n",
      "---------------train actor loss------------- 46.48690101504326\n",
      "---------------Vali actor loss------------- 44.288082\n",
      "100 ***********************************************************************\n",
      "---------------train actor loss------------- 45.51448543866476\n",
      "---------------Vali actor loss------------- 39.961277\n",
      "101 ***********************************************************************\n",
      "---------------train actor loss------------- 44.13160108195411\n",
      "---------------Vali actor loss------------- 48.700394\n",
      "102 ***********************************************************************\n",
      "---------------train actor loss------------- 47.96703561809328\n",
      "---------------Vali actor loss------------- 45.712463\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-b39ad8be180b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBaseline_RankNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m46\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_para\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'baseline_h_dim'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_para\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'baseline_output'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0mtrained_model_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_para\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lambda'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mactor_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_model_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-d1bf3b732fa9>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(baseline_model, actor_model, critic_model, epochs, lamda, beta, gamma)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# train critic model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mcritic_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcritic_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselection_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselection_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mlabel_difference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-53c84db2e28e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_1, selection_1, input_2, selection_2)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0minput_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mresult_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#预测input_2得分\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mresult_2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#input_1比input_2更相关概率\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1608\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "actor_list = []\n",
    "critic_list = []\n",
    "baseline_list = []\n",
    "\n",
    "beta = 0.1\n",
    "gamma = 0.5\n",
    "samples_portion_of_all = 0.0001\n",
    "\n",
    "for k in range(1):\n",
    "\n",
    "    y_train = []\n",
    "    x_train = []\n",
    "    query_id = []\n",
    "    array_train_x1 = []\n",
    "    array_train_x0 = []\n",
    "\n",
    "    path = \"./MQ2008/Fold{}/\".format(k+1)\n",
    "\n",
    "    train_path = path + 'train.txt'\n",
    "    train_loader = get_loader(train_path, batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    vali_path = path + 'vali.txt'\n",
    "    vali_loader = get_loader(vali_path, batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    test_path = path + 'test.txt'\n",
    "    test_loader = get_loader(test_path, batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    actor = Actor(46, model_para['actor_h_dim'], model_para['actor_output'], model_para['n_layer'], model_para['activation'])\n",
    "    critic = Critic_RankNet(46, model_para['critic_h_dim'], model_para['critic_output'])\n",
    "    baseline = Baseline_RankNet(46, model_para['baseline_h_dim'], model_para['baseline_output'])\n",
    "\n",
    "    trained_model_list = train_model(baseline, actor, critic, 1000, model_para['lambda'], beta, gamma)\n",
    "\n",
    "    actor_list.append(trained_model_list[0])\n",
    "    critic_list.append(trained_model_list[1])\n",
    "    baseline_list.append(trained_model_list[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T11:03:05.881398Z",
     "start_time": "2020-11-20T09:28:26.726Z"
    }
   },
   "outputs": [],
   "source": [
    "for k in range(1):    \n",
    "    torch.save(actor_list[k].state_dict(), './tmp_model_saved/sample_0.0001_of_all_balance/***_(beta_0.1_gamma_0.5_epoch_1000_batch_32)_actor_{}.pth'.format(k))\n",
    "    torch.save(critic_list[k].state_dict(), './tmp_model_saved/sample_0.0001_of_all_balance/***_(beta_0.1_gamma_0.5_epoch_1000_batch_32)_critic_{}.pth'.format(k))\n",
    "    torch.save(baseline_list[k].state_dict(), './tmp_model_saved/sample_0.0001_of_all_balance/***_(beta_0.1_gamma_0.5_epoch_1000_batch_32)_baseline_{}.pth'.format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T11:03:33.649072Z",
     "start_time": "2020-11-20T11:03:33.642264Z"
    }
   },
   "outputs": [],
   "source": [
    "model_para = {'lambda':0.3,\n",
    "              'actor_h_dim':300,\n",
    "              'critic_h_dim':200,\n",
    "              'baseline_h_dim':200,\n",
    "              'actor_output' :46,\n",
    "              'critic_output':1,\n",
    "              'baseline_output':1,\n",
    "              'n_layer':3,\n",
    "              'activation':'selu',\n",
    "              'learning_rate':0.0001}\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T21:14:51.183912Z",
     "start_time": "2020-11-20T20:27:06.461585Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/zhang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/zhang/anaconda3/lib/python3.6/site-packages/torch/nn/modules/loss.py:516: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ***********************************************************************\n",
      "---------------train actor loss------------- 0.46651045936677193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:94: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/zhang/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:96: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Vali actor loss------------- 2.6633961\n",
      "2 ***********************************************************************\n",
      "---------------train actor loss------------- 1.536978291761544\n",
      "---------------Vali actor loss------------- 1.2096885\n",
      "3 ***********************************************************************\n",
      "---------------train actor loss------------- 4.372190200620228\n",
      "---------------Vali actor loss------------- 7.478083\n",
      "4 ***********************************************************************\n",
      "---------------train actor loss------------- 5.71598873163263\n",
      "---------------Vali actor loss------------- 3.5142891\n",
      "5 ***********************************************************************\n",
      "---------------train actor loss------------- 8.094109709064165\n",
      "---------------Vali actor loss------------- 10.683511\n",
      "6 ***********************************************************************\n",
      "---------------train actor loss------------- 6.352944477150838\n",
      "---------------Vali actor loss------------- 9.068195\n",
      "7 ***********************************************************************\n",
      "---------------train actor loss------------- 11.325796731644207\n",
      "---------------Vali actor loss------------- 7.8892064\n",
      "8 ***********************************************************************\n",
      "---------------train actor loss------------- 8.832531950540012\n",
      "---------------Vali actor loss------------- 12.766896\n",
      "9 ***********************************************************************\n",
      "---------------train actor loss------------- 8.138522308319807\n",
      "---------------Vali actor loss------------- 11.563961\n",
      "10 ***********************************************************************\n",
      "---------------train actor loss------------- 7.932860980431239\n",
      "---------------Vali actor loss------------- 1.9401202\n",
      "11 ***********************************************************************\n",
      "---------------train actor loss------------- 7.123308518694507\n",
      "---------------Vali actor loss------------- 5.167252\n",
      "12 ***********************************************************************\n",
      "---------------train actor loss------------- 6.816596355289221\n",
      "---------------Vali actor loss------------- 6.8546767\n",
      "13 ***********************************************************************\n",
      "---------------train actor loss------------- 6.79649625511633\n",
      "---------------Vali actor loss------------- 2.4057436\n",
      "14 ***********************************************************************\n",
      "---------------train actor loss------------- 7.118520972215467\n",
      "---------------Vali actor loss------------- 8.10623\n",
      "15 ***********************************************************************\n",
      "---------------train actor loss------------- 5.389020982301897\n",
      "---------------Vali actor loss------------- 3.9430454\n",
      "16 ***********************************************************************\n",
      "---------------train actor loss------------- 6.071941715561682\n",
      "---------------Vali actor loss------------- -0.4521925\n",
      "17 ***********************************************************************\n",
      "---------------train actor loss------------- 3.1436904134849706\n",
      "---------------Vali actor loss------------- 8.304744\n",
      "18 ***********************************************************************\n",
      "---------------train actor loss------------- 4.389659022705422\n",
      "---------------Vali actor loss------------- 4.6588173\n",
      "19 ***********************************************************************\n",
      "---------------train actor loss------------- 5.80648137960169\n",
      "---------------Vali actor loss------------- 10.342132\n",
      "20 ***********************************************************************\n",
      "---------------train actor loss------------- 5.063937293572558\n",
      "---------------Vali actor loss------------- 8.287312\n",
      "21 ***********************************************************************\n",
      "---------------train actor loss------------- 6.804290668004089\n",
      "---------------Vali actor loss------------- 2.924487\n",
      "22 ***********************************************************************\n",
      "---------------train actor loss------------- 7.584850367986494\n",
      "---------------Vali actor loss------------- 8.83156\n",
      "23 ***********************************************************************\n",
      "---------------train actor loss------------- 8.223354799466001\n",
      "---------------Vali actor loss------------- 10.16497\n",
      "24 ***********************************************************************\n",
      "---------------train actor loss------------- 9.350763716217545\n",
      "---------------Vali actor loss------------- 15.318503\n",
      "25 ***********************************************************************\n",
      "---------------train actor loss------------- 10.793634075257513\n",
      "---------------Vali actor loss------------- 18.14913\n",
      "26 ***********************************************************************\n",
      "---------------train actor loss------------- 12.498839259768525\n",
      "---------------Vali actor loss------------- 16.569185\n",
      "27 ***********************************************************************\n",
      "---------------train actor loss------------- 13.512838477889696\n",
      "---------------Vali actor loss------------- 15.998918\n",
      "28 ***********************************************************************\n",
      "---------------train actor loss------------- 14.645863057838547\n",
      "---------------Vali actor loss------------- 14.0478115\n",
      "29 ***********************************************************************\n",
      "---------------train actor loss------------- 14.658199054499468\n",
      "---------------Vali actor loss------------- 9.925832\n",
      "30 ***********************************************************************\n",
      "---------------train actor loss------------- 15.275413584791952\n",
      "---------------Vali actor loss------------- 4.2633533\n",
      "31 ***********************************************************************\n",
      "---------------train actor loss------------- 11.644854411482811\n",
      "---------------Vali actor loss------------- 6.8227806\n",
      "32 ***********************************************************************\n",
      "---------------train actor loss------------- 12.782092485162947\n",
      "---------------Vali actor loss------------- 16.504095\n",
      "33 ***********************************************************************\n",
      "---------------train actor loss------------- 14.170172616218528\n",
      "---------------Vali actor loss------------- 12.754137\n",
      "34 ***********************************************************************\n",
      "---------------train actor loss------------- 13.365589147226679\n",
      "---------------Vali actor loss------------- 14.136864\n",
      "35 ***********************************************************************\n",
      "---------------train actor loss------------- 16.239035567889612\n",
      "---------------Vali actor loss------------- 25.101513\n",
      "36 ***********************************************************************\n",
      "---------------train actor loss------------- 19.373511095427805\n",
      "---------------Vali actor loss------------- 18.87882\n",
      "37 ***********************************************************************\n",
      "---------------train actor loss------------- 15.766581113139788\n",
      "---------------Vali actor loss------------- 15.785727\n",
      "38 ***********************************************************************\n",
      "---------------train actor loss------------- 19.24684472464853\n",
      "---------------Vali actor loss------------- 24.608183\n",
      "39 ***********************************************************************\n",
      "---------------train actor loss------------- 22.20298771974113\n",
      "---------------Vali actor loss------------- 20.30391\n",
      "40 ***********************************************************************\n",
      "---------------train actor loss------------- 16.010293889790773\n",
      "---------------Vali actor loss------------- 25.853277\n",
      "41 ***********************************************************************\n",
      "---------------train actor loss------------- 14.265352072194219\n",
      "---------------Vali actor loss------------- 7.5413923\n",
      "42 ***********************************************************************\n",
      "---------------train actor loss------------- 16.736188701457447\n",
      "---------------Vali actor loss------------- 23.496195\n",
      "43 ***********************************************************************\n",
      "---------------train actor loss------------- 22.326412751442856\n",
      "---------------Vali actor loss------------- 18.006584\n",
      "44 ***********************************************************************\n",
      "---------------train actor loss------------- 19.911408515440094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Vali actor loss------------- 20.18279\n",
      "45 ***********************************************************************\n",
      "---------------train actor loss------------- 19.17302007559273\n",
      "---------------Vali actor loss------------- 24.182774\n",
      "46 ***********************************************************************\n",
      "---------------train actor loss------------- 24.715198716355694\n",
      "---------------Vali actor loss------------- 18.191256\n",
      "47 ***********************************************************************\n",
      "---------------train actor loss------------- 20.48681629697482\n",
      "---------------Vali actor loss------------- 13.496106\n",
      "48 ***********************************************************************\n",
      "---------------train actor loss------------- 20.95834408617682\n",
      "---------------Vali actor loss------------- 17.60757\n",
      "49 ***********************************************************************\n",
      "---------------train actor loss------------- 21.09699961957004\n",
      "---------------Vali actor loss------------- 19.932596\n",
      "50 ***********************************************************************\n",
      "---------------train actor loss------------- 23.39903005129761\n",
      "---------------Vali actor loss------------- 38.86108\n",
      "51 ***********************************************************************\n",
      "---------------train actor loss------------- 22.255521254820955\n",
      "---------------Vali actor loss------------- 29.698238\n",
      "52 ***********************************************************************\n",
      "---------------train actor loss------------- 27.889413175483543\n",
      "---------------Vali actor loss------------- 36.008305\n",
      "53 ***********************************************************************\n",
      "---------------train actor loss------------- 24.24942013124625\n",
      "---------------Vali actor loss------------- 32.935898\n",
      "54 ***********************************************************************\n",
      "---------------train actor loss------------- 23.58154570062955\n",
      "---------------Vali actor loss------------- 18.436634\n",
      "55 ***********************************************************************\n",
      "---------------train actor loss------------- 21.301920929716694\n",
      "---------------Vali actor loss------------- 23.09897\n",
      "56 ***********************************************************************\n",
      "---------------train actor loss------------- 20.555668915311497\n",
      "---------------Vali actor loss------------- 37.50933\n",
      "57 ***********************************************************************\n",
      "---------------train actor loss------------- 23.42306878583299\n",
      "---------------Vali actor loss------------- 26.191051\n",
      "58 ***********************************************************************\n",
      "---------------train actor loss------------- 28.29821724775765\n",
      "---------------Vali actor loss------------- 29.388512\n",
      "59 ***********************************************************************\n",
      "---------------train actor loss------------- 27.570919387042522\n",
      "---------------Vali actor loss------------- 37.836628\n",
      "60 ***********************************************************************\n",
      "---------------train actor loss------------- 28.554467138316895\n",
      "---------------Vali actor loss------------- 33.3909\n",
      "61 ***********************************************************************\n",
      "---------------train actor loss------------- 26.60228794771764\n",
      "---------------Vali actor loss------------- 39.889233\n",
      "62 ***********************************************************************\n",
      "---------------train actor loss------------- 31.077374325858223\n",
      "---------------Vali actor loss------------- 39.55757\n",
      "63 ***********************************************************************\n",
      "---------------train actor loss------------- 32.12093183977736\n",
      "---------------Vali actor loss------------- 29.07482\n",
      "64 ***********************************************************************\n",
      "---------------train actor loss------------- 31.90104573302799\n",
      "---------------Vali actor loss------------- 30.02518\n",
      "65 ***********************************************************************\n",
      "---------------train actor loss------------- 30.3051780462265\n",
      "---------------Vali actor loss------------- 26.656094\n",
      "66 ***********************************************************************\n",
      "---------------train actor loss------------- 32.36416698992252\n",
      "---------------Vali actor loss------------- 43.47562\n",
      "67 ***********************************************************************\n",
      "---------------train actor loss------------- 35.93851959705353\n",
      "---------------Vali actor loss------------- 22.73327\n",
      "68 ***********************************************************************\n",
      "---------------train actor loss------------- 29.00318239091171\n",
      "---------------Vali actor loss------------- 40.941628\n",
      "69 ***********************************************************************\n",
      "---------------train actor loss------------- 31.73110890719626\n",
      "---------------Vali actor loss------------- 27.977234\n",
      "70 ***********************************************************************\n",
      "---------------train actor loss------------- 31.85503242413203\n",
      "---------------Vali actor loss------------- 40.791702\n",
      "71 ***********************************************************************\n",
      "---------------train actor loss------------- 34.793805320229794\n",
      "---------------Vali actor loss------------- 39.31695\n",
      "72 ***********************************************************************\n",
      "---------------train actor loss------------- 37.26796767115593\n",
      "---------------Vali actor loss------------- 38.80301\n",
      "73 ***********************************************************************\n",
      "---------------train actor loss------------- 35.41455554548237\n",
      "---------------Vali actor loss------------- 46.61884\n",
      "74 ***********************************************************************\n",
      "---------------train actor loss------------- 35.84810199340185\n",
      "---------------Vali actor loss------------- 35.768032\n",
      "75 ***********************************************************************\n",
      "---------------train actor loss------------- 36.87962316638894\n",
      "---------------Vali actor loss------------- 40.36502\n",
      "76 ***********************************************************************\n",
      "---------------train actor loss------------- 35.30256394876374\n",
      "---------------Vali actor loss------------- 42.000515\n",
      "77 ***********************************************************************\n",
      "---------------train actor loss------------- 33.13444505135218\n",
      "---------------Vali actor loss------------- 35.874844\n",
      "78 ***********************************************************************\n",
      "---------------train actor loss------------- 37.47789624995656\n",
      "---------------Vali actor loss------------- 37.914234\n",
      "79 ***********************************************************************\n",
      "---------------train actor loss------------- 38.51951716095209\n",
      "---------------Vali actor loss------------- 42.851067\n",
      "80 ***********************************************************************\n",
      "---------------train actor loss------------- 36.118508675860035\n",
      "---------------Vali actor loss------------- 39.78299\n",
      "81 ***********************************************************************\n",
      "---------------train actor loss------------- 42.32688611745834\n",
      "---------------Vali actor loss------------- 56.5474\n",
      "82 ***********************************************************************\n",
      "---------------train actor loss------------- 37.76565714346038\n",
      "---------------Vali actor loss------------- 49.55365\n",
      "83 ***********************************************************************\n",
      "---------------train actor loss------------- 38.400135128034485\n",
      "---------------Vali actor loss------------- 58.767487\n",
      "84 ***********************************************************************\n",
      "---------------train actor loss------------- 40.0657093723615\n",
      "---------------Vali actor loss------------- 39.035446\n",
      "85 ***********************************************************************\n",
      "---------------train actor loss------------- 43.0815333392885\n",
      "---------------Vali actor loss------------- 50.314\n",
      "86 ***********************************************************************\n",
      "---------------train actor loss------------- 43.12294407023324\n",
      "---------------Vali actor loss------------- 55.63404\n",
      "87 ***********************************************************************\n",
      "---------------train actor loss------------- 39.72541304098235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Vali actor loss------------- 42.49132\n",
      "88 ***********************************************************************\n",
      "---------------train actor loss------------- 42.51642469233937\n",
      "---------------Vali actor loss------------- 44.700314\n",
      "89 ***********************************************************************\n",
      "---------------train actor loss------------- 40.55172375175688\n",
      "---------------Vali actor loss------------- 63.294872\n",
      "90 ***********************************************************************\n",
      "---------------train actor loss------------- 44.34873941209581\n",
      "---------------Vali actor loss------------- 48.083748\n",
      "91 ***********************************************************************\n",
      "---------------train actor loss------------- 42.508876691261925\n",
      "---------------Vali actor loss------------- 36.48336\n",
      "92 ***********************************************************************\n",
      "---------------train actor loss------------- 45.316657019986046\n",
      "---------------Vali actor loss------------- 49.94988\n",
      "93 ***********************************************************************\n",
      "---------------train actor loss------------- 41.70534788237678\n",
      "---------------Vali actor loss------------- 47.96947\n",
      "94 ***********************************************************************\n",
      "---------------train actor loss------------- 40.945632216003204\n",
      "---------------Vali actor loss------------- 45.7181\n",
      "95 ***********************************************************************\n",
      "---------------train actor loss------------- 42.1843953066402\n",
      "---------------Vali actor loss------------- 39.425972\n",
      "96 ***********************************************************************\n",
      "---------------train actor loss------------- 46.073755767610336\n",
      "---------------Vali actor loss------------- 41.024616\n",
      "97 ***********************************************************************\n",
      "---------------train actor loss------------- 43.731227934360504\n",
      "---------------Vali actor loss------------- 51.013115\n",
      "98 ***********************************************************************\n",
      "---------------train actor loss------------- 49.21584299537871\n",
      "---------------Vali actor loss------------- 61.606197\n",
      "99 ***********************************************************************\n",
      "---------------train actor loss------------- 44.19687204228507\n",
      "---------------Vali actor loss------------- 44.319744\n",
      "100 ***********************************************************************\n",
      "---------------train actor loss------------- 41.163437532054054\n",
      "---------------Vali actor loss------------- 50.45839\n"
     ]
    }
   ],
   "source": [
    "actor_list = []\n",
    "critic_list = []\n",
    "baseline_list = []\n",
    "\n",
    "beta = 0.5\n",
    "gamma = 1\n",
    "samples_portion_of_all = 0.0001\n",
    "\n",
    "for k in range(1):\n",
    "\n",
    "    y_train = []\n",
    "    x_train = []\n",
    "    query_id = []\n",
    "    array_train_x1 = []\n",
    "    array_train_x0 = []\n",
    "\n",
    "    path = \"./MQ2008/Fold{}/\".format(k+1)\n",
    "\n",
    "    train_path = path + 'train.txt'\n",
    "    train_loader = get_loader(train_path, batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    vali_path = path + 'vali.txt'\n",
    "    vali_loader = get_loader(vali_path, batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    test_path = path + 'test.txt'\n",
    "    test_loader = get_loader(test_path, batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    actor = Actor(46, model_para['actor_h_dim'], model_para['actor_output'], model_para['n_layer'], model_para['activation'])\n",
    "    critic = Critic_RankNet(46, model_para['critic_h_dim'], model_para['critic_output'])\n",
    "    baseline = Baseline_RankNet(46, model_para['baseline_h_dim'], model_para['baseline_output'])\n",
    "\n",
    "    trained_model_list = train_model(baseline, actor, critic, 100, model_para['lambda'], beta, gamma)\n",
    "\n",
    "    actor_list.append(trained_model_list[0])\n",
    "    critic_list.append(trained_model_list[1])\n",
    "    baseline_list.append(trained_model_list[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T21:14:52.273073Z",
     "start_time": "2020-11-20T21:14:52.261359Z"
    }
   },
   "outputs": [],
   "source": [
    "for k in range(1):    \n",
    "    torch.save(actor_list[k].state_dict(), './tmp_model_saved/sample_0.0001_of_all_balance/***_(beta_0.5_gamma_1_epoch_100_batch_32)_actor_{}.pth'.format(k))\n",
    "    torch.save(critic_list[k].state_dict(), './tmp_model_saved/sample_0.0001_of_all_balance/***_(beta_0.5_gamma_1_epoch_100_batch_32)_critic_{}.pth'.format(k))\n",
    "    torch.save(baseline_list[k].state_dict(), './tmp_model_saved/sample_0.0001_of_all_balance/***_(beta_0.5_gamma_1_epoch_100_batch_32)_baseline_{}.pth'.format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "409.091px",
    "left": "21px",
    "top": "110.322px",
    "width": "232.699px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
